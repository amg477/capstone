{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy pyjanitor dateparser pytz ftfy emoji regex rapidfuzz \\\n",
        "             spacy clean-text[gpl] textacy langdetect \\\n",
        "             gensim sentence-transformers bertopic umap-learn hdbscan \\\n",
        "             vaderSentiment \\\n",
        "             networkx cdlib pyvis \\\n",
        "             ydata-profiling\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Jp0fd2xWUnQ8",
        "outputId": "f3b60033-885f-4691-c827-1d65693713ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Collecting pyjanitor\n",
            "  Downloading pyjanitor-0.31.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting dateparser\n",
            "  Downloading dateparser-1.2.2-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (2025.2)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (2024.11.6)\n",
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
            "Collecting textacy\n",
            "  Downloading textacy-0.13.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Collecting bertopic\n",
            "  Downloading bertopic-0.17.3-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.11/dist-packages (0.5.9.post2)\n",
            "Requirement already satisfied: hdbscan in /usr/local/lib/python3.11/dist-packages (0.8.40)\n",
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.5)\n",
            "Collecting cdlib\n",
            "  Downloading cdlib-0.4.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting pyvis\n",
            "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting ydata-profiling\n",
            "  Downloading ydata_profiling-4.16.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting clean-text[gpl]\n",
            "  Downloading clean_text-0.6.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.11/dist-packages (from pyjanitor) (8.4.0)\n",
            "Collecting pandas_flavor (from pyjanitor)\n",
            "  Downloading pandas_flavor-0.7.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.11/dist-packages (from pyjanitor) (1.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pyjanitor) (1.16.0)\n",
            "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.11/dist-packages (from dateparser) (5.3.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy) (0.2.13)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Collecting emoji\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unidecode<2.0.0,>=1.1.1 (from clean-text[gpl])\n",
            "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: cachetools>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from textacy) (5.5.2)\n",
            "Collecting cytoolz>=0.10.1 (from textacy)\n",
            "  Downloading cytoolz-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting floret~=0.10.0 (from textacy)\n",
            "  Downloading floret-0.10.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.1 kB)\n",
            "Collecting jellyfish>=0.8.0 (from textacy)\n",
            "  Downloading jellyfish-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from textacy) (1.5.1)\n",
            "Collecting pyphen>=0.10.0 (from textacy)\n",
            "  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.11/dist-packages (from textacy) (1.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy (from pyjanitor)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.54.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.34.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.1)\n",
            "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (5.24.1)\n",
            "Requirement already satisfied: llvmlite>0.36.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (0.43.0)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (0.5.13)\n",
            "Collecting demon (from cdlib)\n",
            "  Downloading demon-2.0.6-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: python-louvain>=0.16 in /usr/local/lib/python3.11/dist-packages (from cdlib) (0.16)\n",
            "Collecting pulp (from cdlib)\n",
            "  Downloading pulp-3.2.2-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from cdlib) (0.13.2)\n",
            "Collecting eva-lcd (from cdlib)\n",
            "  Downloading eva_lcd-0.1.1-py3-none-any.whl.metadata (731 bytes)\n",
            "Collecting bimlpa (from cdlib)\n",
            "  Downloading bimlpa-0.1.2-py3-none-any.whl.metadata (725 bytes)\n",
            "Collecting python-igraph>=0.10 (from cdlib)\n",
            "  Downloading python_igraph-0.11.9-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting angelcommunity (from cdlib)\n",
            "  Downloading angelcommunity-2.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.11/dist-packages (from cdlib) (1.8.2)\n",
            "Collecting dynetx (from cdlib)\n",
            "  Downloading dynetx-0.3.2-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting thresholdclustering (from cdlib)\n",
            "  Downloading thresholdclustering-1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting python-Levenshtein (from cdlib)\n",
            "  Downloading python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from pyvis) (7.34.0)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvis) (4.1.1)\n",
            "Requirement already satisfied: matplotlib<=3.10,>=3.5 in /usr/local/lib/python3.11/dist-packages (from ydata-profiling) (3.10.0)\n",
            "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from ydata-profiling) (6.0.2)\n",
            "Collecting visions<0.8.2,>=0.7.5 (from visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling)\n",
            "  Downloading visions-0.8.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting htmlmin==0.1.12 (from ydata-profiling)\n",
            "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting phik<0.13,>=0.11.1 (from ydata-profiling)\n",
            "  Downloading phik-0.12.5-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting multimethod<2,>=1.4 (from ydata-profiling)\n",
            "  Downloading multimethod-1.12-py3-none-any.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: statsmodels<1,>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from ydata-profiling) (0.14.5)\n",
            "Requirement already satisfied: typeguard<5,>=3 in /usr/local/lib/python3.11/dist-packages (from ydata-profiling) (4.4.4)\n",
            "Collecting imagehash==4.3.1 (from ydata-profiling)\n",
            "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: wordcloud>=1.9.3 in /usr/local/lib/python3.11/dist-packages (from ydata-profiling) (1.9.4)\n",
            "Collecting dacite>=1.8 (from ydata-profiling)\n",
            "  Downloading dacite-1.9.2-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.11/dist-packages (from imagehash==4.3.1->ydata-profiling) (1.8.0)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from cytoolz>=0.10.1->textacy) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=4.7.0->bertopic) (8.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Collecting igraph==0.11.9 (from python-igraph>=0.10->cdlib)\n",
            "  Downloading igraph-0.11.9-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting texttable>=1.6.2 (from igraph==0.11.9->python-igraph>=0.10->cdlib)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.7.14)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->textacy) (3.6.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels<1,>=0.13.2->ydata-profiling) (1.0.1)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "INFO: pip is looking at multiple versions of thinc to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
            "  Downloading thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
            "  Downloading blis-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.11/dist-packages (from visions<0.8.2,>=0.7.5->visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling) (25.3.0)\n",
            "Collecting puremagic (from visions<0.8.2,>=0.7.5->visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling)\n",
            "  Downloading puremagic-1.30-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from angelcommunity->cdlib) (1.0.0)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.11/dist-packages (from pandas_flavor->pyjanitor) (2025.7.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch->cdlib) (4.3.8)\n",
            "Collecting Levenshtein==0.27.1 (from python-Levenshtein->cdlib)\n",
            "  Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.4)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Downloading pyjanitor-0.31.0-py3-none-any.whl (215 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.4/215.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dateparser-1.2.2-py3-none-any.whl (315 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading textacy-0.13.0-py3-none-any.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bertopic-0.17.3-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cdlib-0.4.0-py3-none-any.whl (263 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.6/263.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ydata_profiling-4.16.1-py2.py3-none-any.whl (400 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.1/400.1 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cytoolz-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dacite-1.9.2-py3-none-any.whl (16 kB)\n",
            "Downloading floret-0.10.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.6/321.6 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jellyfish-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (356 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m356.9/356.9 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multimethod-1.12-py3-none-any.whl (10 kB)\n",
            "Downloading phik-0.12.5-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (679 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m679.0/679.0 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_igraph-0.11.9-py3-none-any.whl (9.2 kB)\n",
            "Downloading igraph-0.11.9-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading visions-0.8.1-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading angelcommunity-2.0.0-py3-none-any.whl (10 kB)\n",
            "Downloading bimlpa-0.1.2-py3-none-any.whl (7.0 kB)\n",
            "Downloading clean_text-0.6.0-py3-none-any.whl (11 kB)\n",
            "Downloading demon-2.0.6-py3-none-any.whl (7.3 kB)\n",
            "Downloading dynetx-0.3.2-py3-none-any.whl (39 kB)\n",
            "Downloading eva_lcd-0.1.1-py3-none-any.whl (9.2 kB)\n",
            "Downloading pandas_flavor-0.7.0-py3-none-any.whl (8.4 kB)\n",
            "Downloading pulp-3.2.2-py3-none-any.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thresholdclustering-1.1-py3-none-any.whl (5.3 kB)\n",
            "Downloading blis-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading puremagic-1.30-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Building wheels for collected packages: emoji, langdetect, htmlmin\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171031 sha256=0c29e2f19e1df7b6d60ddd50759ff4c44452a99bcdc2f736ab4ccfe234a45931\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/22/e5/b69726d5e1a19795ecd3b3e7464b16c0f1d019aa94ff1c8578\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=e7e194dac3acc387b4df7415acecd83723f693a099da9d869191d35f4442fb88\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27081 sha256=d0357aca4d6ec70b1648f47852998edb738ece85ce5b6e9e8338b04a6da0a4b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/55/1a/19cd535375ed1ede0c996405ebffe34b196d78e2d9545723a2\n",
            "Successfully built emoji langdetect htmlmin\n",
            "Installing collected packages: texttable, puremagic, htmlmin, emoji, unidecode, rapidfuzz, pyphen, pulp, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, multimethod, langdetect, jellyfish, jedi, igraph, ftfy, demon, dacite, cytoolz, vaderSentiment, thresholdclustering, scipy, python-igraph, nvidia-cusparse-cu12, nvidia-cudnn-cu12, Levenshtein, floret, eva-lcd, dynetx, dateparser, clean-text, blis, visions, pyvis, python-Levenshtein, nvidia-cusolver-cu12, imagehash, gensim, angelcommunity, thinc, phik, pandas_flavor, bimlpa, ydata-profiling, pyjanitor, cdlib, textacy, bertopic\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.0\n",
            "    Uninstalling scipy-1.16.0:\n",
            "      Successfully uninstalled scipy-1.16.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 1.3.0\n",
            "    Uninstalling blis-1.3.0:\n",
            "      Successfully uninstalled blis-1.3.0\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.3.6\n",
            "    Uninstalling thinc-8.3.6:\n",
            "      Successfully uninstalled thinc-8.3.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Levenshtein-0.27.1 angelcommunity-2.0.0 bertopic-0.17.3 bimlpa-0.1.2 blis-1.2.1 cdlib-0.4.0 clean-text-0.6.0 cytoolz-1.0.1 dacite-1.9.2 dateparser-1.2.2 demon-2.0.6 dynetx-0.3.2 emoji-1.7.0 eva-lcd-0.1.1 floret-0.10.5 ftfy-6.3.1 gensim-4.3.3 htmlmin-0.1.12 igraph-0.11.9 imagehash-4.3.1 jedi-0.19.2 jellyfish-1.2.0 langdetect-1.0.9 multimethod-1.12 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pandas_flavor-0.7.0 phik-0.12.5 pulp-3.2.2 puremagic-1.30 pyjanitor-0.31.0 pyphen-0.17.2 python-Levenshtein-0.27.1 python-igraph-0.11.9 pyvis-0.3.2 rapidfuzz-3.13.0 scipy-1.13.1 textacy-0.13.0 texttable-1.7.0 thinc-8.3.4 thresholdclustering-1.1 unidecode-1.4.0 vaderSentiment-3.3.2 visions-0.8.1 ydata-profiling-4.16.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "3fc34cfa6c6c47d6925077037c03fa4f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "import warnings, re\n",
        "from typing import Optional, List\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import janitor\n",
        "from dateparser import parse as dparse\n",
        "import ftfy, emoji\n",
        "import networkx as nx\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2ggWEZujIwP",
        "outputId": "3ab91d8d-2c34-4334-cefc-589feb0af445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/cli/_util.py:23: DeprecationWarning: Importing 'parser.split_arg_string' is deprecated, it will only be available in 'shell_completion' in Click 9.0.\n",
            "  from click.parser import split_arg_string\n",
            "/usr/local/lib/python3.11/dist-packages/weasel/util/config.py:8: DeprecationWarning: Importing 'parser.split_arg_string' is deprecated, it will only be available in 'shell_completion' in Click 9.0.\n",
            "  from click.parser import split_arg_string\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s_data = pd.read_csv('/content/saved_search_jul7day_ex.csv')"
      ],
      "metadata": {
        "id": "zi0mgFP2b4sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        },
        "id": "L5CjMDk1cQLI",
        "outputId": "852b1654-52d2-4fdb-9456-d251d3442bb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    ARTICLE_ID          PUBLICATION   LOAD_DATE        COUNTRY  \\\n",
              "0  19679200667  Dakota Broadcasting  2025-07-31  United States   \n",
              "1  19679189805      Life Technology  2025-07-31  United States   \n",
              "2  19679163086             Htv10 Tv  2025-07-31  United States   \n",
              "3  19679152080           Archynewsy  2025-07-31  United States   \n",
              "4  19679132677            ReliefWeb  2025-07-31  United States   \n",
              "\n",
              "                                            HEADLINE  \\\n",
              "0  South Dakota DANR announces are quality alert ...   \n",
              "1  Study Reveals Statistical Modeling Enhances NT...   \n",
              "2  DR. MARLEN J. TRUJILLO, CEO OF SPRING BRANCH C...   \n",
              "3   Samcheok City Health Survey 2025: Excellent Area   \n",
              "4                       Health & Wellness Caseworker   \n",
              "\n",
              "                                        ARTICLE TEXT         AUTHOR  \\\n",
              "0  The South Dakota Department of Agriculture and...     uncredited   \n",
              "1  Study migrants Italy statistical modeling impr...     uncredited   \n",
              "2    Joining the Harris Health Board is a unique ...     uncredited   \n",
              "3    Samcheok City Recognized for Excellence in R...  Natalie Singh   \n",
              "4    Job Overview:  Our Community Health and Well...     uncredited   \n",
              "\n",
              "     SOURCE TYPE                                               TAGS  \\\n",
              "0  Regional News  Air Quality,Climate Change Impacts on Human He...   \n",
              "1       Consumer  Google,Google News,Publicis Groupe,PressReader...   \n",
              "2  Regional News  Harris Health System,Facebook,LinkedIn,Governm...   \n",
              "3   General News  Ministry of Health and Prevention (UAE),Corner...   \n",
              "4     Government  Well,IRC,Community Mental Health,Crisis,Famili...   \n",
              "\n",
              "   CIRCULATION SIZE  ... EDITION  \\\n",
              "0               939  ...     NaN   \n",
              "1              2612  ...     NaN   \n",
              "2              2886  ...     NaN   \n",
              "3              2029  ...     NaN   \n",
              "4            653149  ...     NaN   \n",
              "\n",
              "                                                LINK CUSTOM TAGS  \\\n",
              "0  https://dakotabroadcasting.com/south-dakota-da...         NaN   \n",
              "1  https://www.lifetechnology.com/blogs/life-tech...         NaN   \n",
              "2  https://www.htv10.tv/story/52967307/dr-marlen-...         NaN   \n",
              "3  https://www.archynewsy.com/samcheok-city-healt...         NaN   \n",
              "4  https://reliefweb.int/job/4168098/health-welln...         NaN   \n",
              "\n",
              "   Last Smoke Campaign SENTIMENT  Health Campaign SENTIMENT  \\\n",
              "0                            NaN                        NaN   \n",
              "1                            NaN                        NaN   \n",
              "2                            NaN                        NaN   \n",
              "3                            NaN                        NaN   \n",
              "4                            NaN                        NaN   \n",
              "\n",
              "  Public Health SENTIMENT World Health Leadership SENTIMENT  \\\n",
              "0                 Neutral                               NaN   \n",
              "1                Positive                               NaN   \n",
              "2                 Neutral                               NaN   \n",
              "3                Positive                               NaN   \n",
              "4                Positive                               NaN   \n",
              "\n",
              "  State Healthcare Funding SENTIMENT Penrose Enquiry SENTIMENT  \\\n",
              "0                                NaN                       NaN   \n",
              "1                                NaN                       NaN   \n",
              "2                                NaN                       NaN   \n",
              "3                                NaN                       NaN   \n",
              "4                                NaN                       NaN   \n",
              "\n",
              "   NHS Reform SENTIMENT  \n",
              "0                   NaN  \n",
              "1                   NaN  \n",
              "2                   NaN  \n",
              "3                   NaN  \n",
              "4                   NaN  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f8330cc2-56c7-4de8-aa0c-3168ca752472\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ARTICLE_ID</th>\n",
              "      <th>PUBLICATION</th>\n",
              "      <th>LOAD_DATE</th>\n",
              "      <th>COUNTRY</th>\n",
              "      <th>HEADLINE</th>\n",
              "      <th>ARTICLE TEXT</th>\n",
              "      <th>AUTHOR</th>\n",
              "      <th>SOURCE TYPE</th>\n",
              "      <th>TAGS</th>\n",
              "      <th>CIRCULATION SIZE</th>\n",
              "      <th>...</th>\n",
              "      <th>EDITION</th>\n",
              "      <th>LINK</th>\n",
              "      <th>CUSTOM TAGS</th>\n",
              "      <th>Last Smoke Campaign SENTIMENT</th>\n",
              "      <th>Health Campaign SENTIMENT</th>\n",
              "      <th>Public Health SENTIMENT</th>\n",
              "      <th>World Health Leadership SENTIMENT</th>\n",
              "      <th>State Healthcare Funding SENTIMENT</th>\n",
              "      <th>Penrose Enquiry SENTIMENT</th>\n",
              "      <th>NHS Reform SENTIMENT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19679200667</td>\n",
              "      <td>Dakota Broadcasting</td>\n",
              "      <td>2025-07-31</td>\n",
              "      <td>United States</td>\n",
              "      <td>South Dakota DANR announces are quality alert ...</td>\n",
              "      <td>The South Dakota Department of Agriculture and...</td>\n",
              "      <td>uncredited</td>\n",
              "      <td>Regional News</td>\n",
              "      <td>Air Quality,Climate Change Impacts on Human He...</td>\n",
              "      <td>939</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://dakotabroadcasting.com/south-dakota-da...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19679189805</td>\n",
              "      <td>Life Technology</td>\n",
              "      <td>2025-07-31</td>\n",
              "      <td>United States</td>\n",
              "      <td>Study Reveals Statistical Modeling Enhances NT...</td>\n",
              "      <td>Study migrants Italy statistical modeling impr...</td>\n",
              "      <td>uncredited</td>\n",
              "      <td>Consumer</td>\n",
              "      <td>Google,Google News,Publicis Groupe,PressReader...</td>\n",
              "      <td>2612</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.lifetechnology.com/blogs/life-tech...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Positive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19679163086</td>\n",
              "      <td>Htv10 Tv</td>\n",
              "      <td>2025-07-31</td>\n",
              "      <td>United States</td>\n",
              "      <td>DR. MARLEN J. TRUJILLO, CEO OF SPRING BRANCH C...</td>\n",
              "      <td>Joining the Harris Health Board is a unique ...</td>\n",
              "      <td>uncredited</td>\n",
              "      <td>Regional News</td>\n",
              "      <td>Harris Health System,Facebook,LinkedIn,Governm...</td>\n",
              "      <td>2886</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.htv10.tv/story/52967307/dr-marlen-...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>19679152080</td>\n",
              "      <td>Archynewsy</td>\n",
              "      <td>2025-07-31</td>\n",
              "      <td>United States</td>\n",
              "      <td>Samcheok City Health Survey 2025: Excellent Area</td>\n",
              "      <td>Samcheok City Recognized for Excellence in R...</td>\n",
              "      <td>Natalie Singh</td>\n",
              "      <td>General News</td>\n",
              "      <td>Ministry of Health and Prevention (UAE),Corner...</td>\n",
              "      <td>2029</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.archynewsy.com/samcheok-city-healt...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Positive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19679132677</td>\n",
              "      <td>ReliefWeb</td>\n",
              "      <td>2025-07-31</td>\n",
              "      <td>United States</td>\n",
              "      <td>Health &amp; Wellness Caseworker</td>\n",
              "      <td>Job Overview:  Our Community Health and Well...</td>\n",
              "      <td>uncredited</td>\n",
              "      <td>Government</td>\n",
              "      <td>Well,IRC,Community Mental Health,Crisis,Famili...</td>\n",
              "      <td>653149</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://reliefweb.int/job/4168098/health-welln...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Positive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8330cc2-56c7-4de8-aa0c-3168ca752472')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f8330cc2-56c7-4de8-aa0c-3168ca752472 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f8330cc2-56c7-4de8-aa0c-3168ca752472');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-829569e7-4b93-49b0-856a-268dce911dfe\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-829569e7-4b93-49b0-856a-268dce911dfe')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-829569e7-4b93-49b0-856a-268dce911dfe button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "s_data"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s_data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaa98nNCcYGt",
        "outputId": "b5643ac7-1787-4699-d6d2-bf91a73f9ce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ARTICLE_ID', 'PUBLICATION', 'LOAD_DATE', 'COUNTRY', 'HEADLINE',\n",
              "       'ARTICLE TEXT', 'AUTHOR', 'SOURCE TYPE', 'TAGS', 'CIRCULATION SIZE',\n",
              "       'CHANNEL', 'EDITION', 'LINK', 'CUSTOM TAGS',\n",
              "       'Last Smoke Campaign SENTIMENT', 'Health Campaign SENTIMENT',\n",
              "       'Public Health SENTIMENT', 'World Health Leadership SENTIMENT',\n",
              "       'State Healthcare Funding SENTIMENT', 'Penrose Enquiry SENTIMENT',\n",
              "       'NHS Reform SENTIMENT'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTjS_hu3dvAR",
        "outputId": "aab3af29-f322-4581-829e-13e73d5337a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 21 columns):\n",
            " #   Column                              Non-Null Count  Dtype  \n",
            "---  ------                              --------------  -----  \n",
            " 0   ARTICLE_ID                          1000 non-null   int64  \n",
            " 1   PUBLICATION                         1000 non-null   object \n",
            " 2   LOAD_DATE                           1000 non-null   object \n",
            " 3   COUNTRY                             1000 non-null   object \n",
            " 4   HEADLINE                            1000 non-null   object \n",
            " 5   ARTICLE TEXT                        1000 non-null   object \n",
            " 6   AUTHOR                              1000 non-null   object \n",
            " 7   SOURCE TYPE                         1000 non-null   object \n",
            " 8   TAGS                                1000 non-null   object \n",
            " 9   CIRCULATION SIZE                    1000 non-null   int64  \n",
            " 10  CHANNEL                             1000 non-null   object \n",
            " 11  EDITION                             0 non-null      float64\n",
            " 12  LINK                                1000 non-null   object \n",
            " 13  CUSTOM TAGS                         0 non-null      float64\n",
            " 14  Last Smoke Campaign SENTIMENT       0 non-null      float64\n",
            " 15  Health Campaign SENTIMENT           4 non-null      object \n",
            " 16  Public Health SENTIMENT             987 non-null    object \n",
            " 17  World Health Leadership SENTIMENT   68 non-null     object \n",
            " 18  State Healthcare Funding SENTIMENT  5 non-null      object \n",
            " 19  Penrose Enquiry SENTIMENT           0 non-null      float64\n",
            " 20  NHS Reform SENTIMENT                0 non-null      float64\n",
            "dtypes: float64(5), int64(2), object(14)\n",
            "memory usage: 164.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### checking NAs\n",
        "s_data.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "id": "5pGxnkQBjt4B",
        "outputId": "024f0b9b-5b36-4b2f-e481-0e0d7dfa15b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ARTICLE_ID                               0\n",
              "PUBLICATION                              0\n",
              "LOAD_DATE                                0\n",
              "COUNTRY                                  0\n",
              "HEADLINE                                 0\n",
              "ARTICLE TEXT                             0\n",
              "AUTHOR                                   0\n",
              "SOURCE TYPE                              0\n",
              "TAGS                                     0\n",
              "CIRCULATION SIZE                         0\n",
              "CHANNEL                                  0\n",
              "EDITION                               1000\n",
              "LINK                                     0\n",
              "CUSTOM TAGS                           1000\n",
              "Last Smoke Campaign SENTIMENT         1000\n",
              "Health Campaign SENTIMENT              996\n",
              "Public Health SENTIMENT                 13\n",
              "World Health Leadership SENTIMENT      932\n",
              "State Healthcare Funding SENTIMENT     995\n",
              "Penrose Enquiry SENTIMENT             1000\n",
              "NHS Reform SENTIMENT                  1000\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ARTICLE_ID</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PUBLICATION</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LOAD_DATE</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>COUNTRY</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HEADLINE</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ARTICLE TEXT</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AUTHOR</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SOURCE TYPE</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TAGS</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CIRCULATION SIZE</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CHANNEL</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EDITION</th>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LINK</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CUSTOM TAGS</th>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Last Smoke Campaign SENTIMENT</th>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Health Campaign SENTIMENT</th>\n",
              "      <td>996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Public Health SENTIMENT</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>World Health Leadership SENTIMENT</th>\n",
              "      <td>932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>State Healthcare Funding SENTIMENT</th>\n",
              "      <td>995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Penrose Enquiry SENTIMENT</th>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NHS Reform SENTIMENT</th>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### can drop unnecessary columns such as majority of sentiment columns, Edition, custom tags,"
      ],
      "metadata": {
        "id": "DXXw2EqukHR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### prioritizing the informative column\n",
        "core_cols = [\n",
        "    \"ARTICLE_ID\", \"PUBLICATION\", \"LOAD_DATE\", \"COUNTRY\", \"HEADLINE\",\n",
        "    \"ARTICLE TEXT\", \"AUTHOR\", \"SOURCE TYPE\", \"TAGS\", \"CIRCULATION SIZE\",\n",
        "    \"CHANNEL\", \"LINK\",\n",
        "    \"Public Health SENTIMENT\", \"World Health Leadership SENTIMENT\",\n",
        "]"
      ],
      "metadata": {
        "id": "3zUW5slXjLU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## saving the dropped columns\n",
        "DROP_COLS = [\n",
        "    \"EDITION\", \"CUSTOM TAGS\",\n",
        "    \"Last Smoke Campaign SENTIMENT\", \"Health Campaign SENTIMENT\",\n",
        "    \"State Healthcare Funding SENTIMENT\", \"Penrose Enquiry SENTIMENT\",\n",
        "    \"NHS Reform SENTIMENT\"\n",
        "]"
      ],
      "metadata": {
        "id": "X1byjiFrjW6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SENT_MAP = {\"positive\": 1.0, \"neutral\": 0.0, \"negative\": -1.0}"
      ],
      "metadata": {
        "id": "p4JtAgfgkw3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "****"
      ],
      "metadata": {
        "id": "jrMwTHXYlekU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### building helpers to preprocess the dataset"
      ],
      "metadata": {
        "id": "-R9mr2Nelgsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _to_date(series: pd.Series) -> pd.Series:\n",
        "    def _p(x):\n",
        "        if pd.isna(x) or str(x).strip()==\"\":\n",
        "            return pd.NaT\n",
        "        dt = dparse(str(x))\n",
        "        return pd.NaT if dt is None else pd.Timestamp(dt.date())\n",
        "    return series.apply(_p)\n",
        "\n",
        "def _clean_text(s: str) -> str:\n",
        "    s = ftfy.fix_text(str(s))\n",
        "    s = emoji.replace_emoji(s, replace=\"\")\n",
        "    s = re.sub(r\"http\\S+|\\S+@\\S+|#\\w+|@\\w+\", \" \")\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "def _split_tags(x: str) -> list:\n",
        "    if not isinstance(x, str) or not x.strip():\n",
        "        return []\n",
        "    return [t.strip() for t in x.split(\",\") if t.strip()]\n",
        "\n",
        "def _sent_label_to_num(lbl) -> float:\n",
        "    if not isinstance(lbl, str): return np.nan\n",
        "    return SENT_MAP.get(lbl.strip().lower(), np.nan)"
      ],
      "metadata": {
        "id": "pfYPU2cF0wsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preprocessing"
      ],
      "metadata": {
        "id": "gLHvhy7105kt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(df: pd.DataFrame) -> pd.DataFrame:\n",
        "\n",
        "    for c in core_cols:\n",
        "        if c not in df.columns:\n",
        "            df[c] = np.nan\n",
        "    df = df[core_cols + [c for c in DROP_COLS if c in df.columns]]\n",
        "    df = df.drop(columns=[c for c in DROP_COLS if c in df.columns], errors=\"ignore\")\n",
        "\n",
        "\n",
        "    df = (df\n",
        "          .remove_empty()\n",
        "          .drop_duplicates(subset=[\"ARTICLE_ID\"], ignore_index=True))\n",
        "\n",
        "\n",
        "    df[\"LOAD_DATE\"] = _to_date(df[\"LOAD_DATE\"])\n",
        "    df[\"DAY\"]   = df[\"LOAD_DATE\"]\n",
        "    df[\"WEEK\"]  = df[\"LOAD_DATE\"].dt.to_period(\"W\").dt.start_time\n",
        "    df[\"MONTH\"] = df[\"LOAD_DATE\"].dt.to_period(\"M\").dt.start_time\n",
        "\n",
        "\n",
        "    df[\"ARTICLE_TEXT_CLEAN\"] = df[\"ARTICLE TEXT\"].astype(str).map(_clean_text)\n",
        "    df[\"HEADLINE_CLEAN\"]     = df[\"HEADLINE\"].astype(str).map(_clean_text)\n",
        "\n",
        "\n",
        "    df[\"TAGS_LIST\"] = df[\"TAGS\"].apply(_split_tags)\n",
        "\n",
        "\n",
        "    df[\"CIRCULATION_SIZE_NUM\"] = pd.to_numeric(df[\"CIRCULATION SIZE\"], errors=\"coerce\")\n",
        "\n",
        "\n",
        "    for col in [\"Public Health SENTIMENT\",\"World Health Leadership SENTIMENT\"]:\n",
        "        df[f\"{col}__num\"] = df[col].map(_sent_label_to_num)\n",
        "\n",
        "    def _overall_sent(row):\n",
        "        ph = row.get(\"Public Health SENTIMENT__num\", np.nan)\n",
        "        wh = row.get(\"World Health Leadership SENTIMENT__num\", np.nan)\n",
        "        if pd.notna(ph): return ph\n",
        "        if pd.notna(wh): return wh\n",
        "        return np.nan\n",
        "\n",
        "    df[\"SENT_OVERALL_NUM\"] = df.apply(_overall_sent, axis=1)\n",
        "    df[\"SENT_OVERALL_BIN\"] = pd.Series(np.select(\n",
        "        [df[\"SENT_OVERALL_NUM\"]>0.05, df[\"SENT_OVERALL_NUM\"]<-0.05],\n",
        "        [\"Positive\",\"Negative\"],\n",
        "        default=\"Neutral\"\n",
        "    ))\n",
        "\n",
        "\n",
        "    df[\"WORD_LEN\"] = df[\"ARTICLE_TEXT_CLEAN\"].str.split().map(len)\n",
        "    df[\"CHAR_LEN\"] = df[\"ARTICLE_TEXT_CLEAN\"].str.len()\n",
        "\n",
        "    return df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "GWqPWr43011V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def derive_conversion_flag(\n",
        "    df: pd.DataFrame,\n",
        "    text_keywords: Optional[Iterable[str]] = None,\n",
        "    tag_includes: Optional[Iterable[str]] = None,\n",
        "    publication_includes: Optional[Iterable[str]] = None,\n",
        "    min_circulation_quantile: Optional[float] = None,\n",
        "    col_name: str = \"CONVERSION\"\n",
        ") -> pd.DataFrame:\n",
        "    conv = np.zeros(len(df), dtype=int)\n",
        "\n",
        "\n",
        "    if text_keywords:\n",
        "        pattern = re.compile(\"|\".join([re.escape(k) for k in text_keywords]), flags=re.IGNORECASE)\n",
        "        mask_text = df[\"HEADLINE_CLEAN\"].str.contains(pattern) | df[\"ARTICLE_TEXT_CLEAN\"].str.contains(pattern)\n",
        "        conv = np.where(mask_text, 1, conv)\n",
        "\n",
        "\n",
        "    if tag_includes:\n",
        "        tag_set = {t.lower() for t in tag_includes}\n",
        "        mask_tag = df[\"TAGS_LIST\"].apply(lambda lst: any(t.lower() in tag_set for t in lst))\n",
        "        conv = np.where(mask_tag, 1, conv)\n",
        "\n",
        "\n",
        "    if publication_includes:\n",
        "        pub_set = {p.lower() for p in publication_includes}\n",
        "        mask_pub = df[\"PUBLICATION\"].astype(str).str.lower().isin(pub_set)\n",
        "        conv = np.where(mask_pub, 1, conv)\n",
        "\n",
        "\n",
        "    if min_circulation_quantile is not None:\n",
        "        q = df[\"CIRCULATION_SIZE_NUM\"].quantile(min_circulation_quantile)\n",
        "        conv = np.where((df[\"CIRCULATION_SIZE_NUM\"] >= q) & (conv==1), 1, 0)\n",
        "\n",
        "    df[col_name] = conv.astype(int)\n",
        "    return df"
      ],
      "metadata": {
        "id": "GV0DpU4A1Zyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "Yeip1CWIv8bS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eda_tables(df: pd.DataFrame) -> Dict[str, pd.DataFrame]:\n",
        "    out = {}\n",
        "\n",
        "    out[\"top_publications\"] = (df.groupby(\"PUBLICATION\")[\"ARTICLE_ID\"]\n",
        "                                 .count().rename(\"count\").reset_index()\n",
        "                                 .sort_values(\"count\", ascending=False).head(30))\n",
        "    out[\"sources_count_avg_circ\"] = (\n",
        "        df.groupby(\"PUBLICATION\", dropna=False)\n",
        "          .agg(articles=(\"ARTICLE_ID\",\"count\"),\n",
        "               avg_circ=(\"CIRCULATION_SIZE_NUM\",\"mean\"))\n",
        "          .reset_index()\n",
        "          .sort_values([\"articles\",\"avg_circ\"], ascending=[False, False])\n",
        "    )\n",
        "    out[\"by_source_type\"] = (df.groupby(\"SOURCE TYPE\")[\"ARTICLE_ID\"]\n",
        "                               .count().rename(\"count\").reset_index()\n",
        "                               .sort_values(\"count\", ascending=False))\n",
        "    out[\"by_channel\"] = (df.groupby(\"CHANNEL\")[\"ARTICLE_ID\"]\n",
        "                           .count().rename(\"count\").reset_index()\n",
        "                           .sort_values(\"count\", ascending=False))\n",
        "    out[\"by_country\"] = (df.groupby(\"COUNTRY\")[\"ARTICLE_ID\"]\n",
        "                           .count().rename(\"count\").reset_index()\n",
        "                           .sort_values(\"count\", ascending=False))\n",
        "\n",
        "    out[\"volume_daily\"] = (df.groupby(\"DAY\")[\"ARTICLE_ID\"]\n",
        "                             .count().rename(\"count\").reset_index()\n",
        "                             .sort_values(\"DAY\"))\n",
        "    out[\"volume_weekly\"] = (df.groupby(\"WEEK\")[\"ARTICLE_ID\"]\n",
        "                              .count().rename(\"count\").reset_index()\n",
        "                              .sort_values(\"WEEK\"))\n",
        "    out[\"volume_monthly\"] = (df.groupby(\"MONTH\")[\"ARTICLE_ID\"]\n",
        "                               .count().rename(\"count\").reset_index()\n",
        "                               .sort_values(\"MONTH\"))\n",
        "\n",
        "    tags_explode = df[[\"ARTICLE_ID\",\"TAGS_LIST\"]].explode(\"TAGS_LIST\")\n",
        "    out[\"top_tags\"] = (tags_explode[tags_explode[\"TAGS_LIST\"].notna() & (tags_explode[\"TAGS_LIST\"]!=\"\")]\n",
        "                         .groupby(\"TAGS_LIST\")[\"ARTICLE_ID\"].count()\n",
        "                         .rename(\"count\").reset_index()\n",
        "                         .sort_values(\"count\", ascending=False).head(50))\n",
        "\n",
        "    out[\"overall_sentiment\"] = (df[\"SENT_OVERALL_BIN\"]\n",
        "                                .value_counts(dropna=False)\n",
        "                                .rename_axis(\"overall_bin\")\n",
        "                                .reset_index(name=\"count\"))\n",
        "    sent_keep = [\"Public Health SENTIMENT\",\"World Health Leadership SENTIMENT\"]\n",
        "    sent_long = df[[\"ARTICLE_ID\"] + sent_keep].melt(\n",
        "        id_vars=[\"ARTICLE_ID\"], var_name=\"topic\", value_name=\"label\"\n",
        "    ).dropna(subset=[\"label\"])\n",
        "    out[\"sentiment_by_topic\"] = (sent_long.groupby([\"topic\",\"label\"])[\"ARTICLE_ID\"]\n",
        "                                 .count().rename(\"count\").reset_index()\n",
        "                                 .sort_values([\"topic\",\"count\"], ascending=[True, False]))\n",
        "\n",
        "    if \"CONVERSION\" in df.columns:\n",
        "        conv_rate = pd.DataFrame({\n",
        "            \"metric\":[\"total_articles\",\"conversion_articles\",\"conversion_rate\"],\n",
        "            \"value\":[len(df), int(df[\"CONVERSION\"].sum()),\n",
        "                     (df[\"CONVERSION\"].sum()/len(df) if len(df) else np.nan)]\n",
        "        })\n",
        "        out[\"conversion_summary\"] = conv_rate\n",
        "    return out"
      ],
      "metadata": {
        "id": "LpKbnwtA1t47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def keywords_high_circ_conversion(\n",
        "    df: pd.DataFrame,\n",
        "    conv_col: str = \"CONVERSION\",\n",
        "    circ_col: str = \"CIRCULATION_SIZE_NUM\",\n",
        "    text_col: str = \"ARTICLE_TEXT_CLEAN\",\n",
        "    quantile: float = 0.75,\n",
        "    n_terms: int = 20,\n",
        "    ngram_range: Tuple[int,int] = (1,2),\n",
        ") -> pd.DataFrame:\n",
        "    if conv_col in df.columns and df[conv_col].sum() > 0:\n",
        "        subset = df[(df[conv_col]==1)]\n",
        "    else:\n",
        "        subset = df.copy()\n",
        "\n",
        "    q = subset[circ_col].quantile(quantile)\n",
        "    subset = subset[subset[circ_col] >= q]\n",
        "    corpus = subset[text_col].fillna(\"\").tolist()\n",
        "    if not corpus:\n",
        "        return pd.DataFrame(columns=[\"term\",\"count\"])\n",
        "\n",
        "    vec = CountVectorizer(lowercase=True, stop_words=\"english\",\n",
        "                          max_df=0.9, min_df=2, ngram_range=ngram_range)\n",
        "    X = vec.fit_transform(corpus)\n",
        "    counts = np.asarray(X.sum(axis=0)).ravel()\n",
        "    terms = np.array(vec.get_feature_names_out())\n",
        "    order = counts.argsort()[::-1][:n_terms]\n",
        "    return pd.DataFrame({\"term\": terms[order], \"count\": counts[order]})"
      ],
      "metadata": {
        "id": "FMMATRhM2AAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "****"
      ],
      "metadata": {
        "id": "yQh3kL_35cNZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Network Analysis Tables"
      ],
      "metadata": {
        "id": "BUum1w1F5XR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eda_network(df: pd.DataFrame, sample_n: int = 2000, min_cooccurrences: int = 2):\n",
        "    n = min(sample_n, len(df))\n",
        "    texts = df[\"ARTICLE_TEXT_CLEAN\"].head(n).tolist()\n",
        "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"lemmatizer\"])\n",
        "    G = nx.Graph()\n",
        "    for t in texts:\n",
        "        doc = nlp(t[:2000])\n",
        "        ents = list({e.text.strip() for e in doc.ents if e.label_ in {\"PERSON\",\"ORG\"}})\n",
        "        for i in range(len(ents)):\n",
        "            for j in range(i+1, len(ents)):\n",
        "                a, b = sorted([ents[i], ents[j]])\n",
        "                if G.has_edge(a,b):\n",
        "                    G[a][b][\"weight\"] += 1\n",
        "                else:\n",
        "                    G.add_edge(a,b, weight=1)\n",
        "\n",
        "    to_remove = [(u,v) for u,v,w in G.edges(data=\"weight\") if w < min_cooccurrences]\n",
        "    G.remove_edges_from(to_remove)\n",
        "    G.remove_nodes_from([n for n in list(G.nodes) if G.degree(n)==0])\n",
        "\n",
        "\n",
        "    if G.number_of_nodes()==0:\n",
        "        summary = pd.DataFrame(columns=[\"node\",\"degree\",\"betweenness\"])\n",
        "    else:\n",
        "        deg = dict(G.degree())\n",
        "        bet = nx.betweenness_centrality(G)\n",
        "        summary = (pd.DataFrame({\"node\": list(G.nodes),\n",
        "                                 \"degree\": [deg[n] for n in G.nodes],\n",
        "                                 \"betweenness\": [bet[n] for n in G.nodes]})\n",
        "                   .sort_values([\"betweenness\",\"degree\"], ascending=False)\n",
        "                   .reset_index(drop=True))\n",
        "    return G, summary"
      ],
      "metadata": {
        "id": "cRUrZhp72JxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_network_clean(G, net_summary, top_n=40, label_top=12, edge_keep_pct=50, savepath=\"network_top40_clean.png\"):\n",
        "    if G is None or net_summary is None or net_summary.empty or G.number_of_nodes()==0:\n",
        "        return\n",
        "    top_nodes = net_summary.head(top_n)[\"node\"].tolist()\n",
        "    SG = G.subgraph(top_nodes).copy()\n",
        "    if SG.number_of_nodes()==0: return\n",
        "\n",
        "    comps = list(nx.connected_components(SG))\n",
        "    if not comps: return\n",
        "    SG = SG.subgraph(max(comps, key=len)).copy()\n",
        "    if SG.number_of_edges()==0: return\n",
        "\n",
        "    weights = np.array([SG[u][v].get(\"weight\",1.0) for u,v in SG.edges()])\n",
        "    thresh = np.percentile(weights, 100 - edge_keep_pct)  # keep top X%\n",
        "    SG.remove_edges_from([(u,v) for u,v in SG.edges() if SG[u][v].get(\"weight\",1.0) < thresh])\n",
        "    SG.remove_nodes_from([n for n in list(SG.nodes) if SG.degree(n)==0])\n",
        "    if SG.number_of_nodes()==0: return\n",
        "\n",
        "    pos = nx.spring_layout(SG, seed=42, iterations=200)\n",
        "    bet = nx.betweenness_centrality(SG)\n",
        "    ranked = sorted(SG.nodes(), key=lambda n: bet.get(n,0.0), reverse=True)\n",
        "    sizes_map = {n:s for n,s in zip(ranked, np.linspace(400,2200,num=len(ranked)))}\n",
        "    sizes = [sizes_map[n] for n in SG.nodes()]\n",
        "    ewidths = [0.6 + np.log1p(SG[u][v].get(\"weight\",1.0)) for u,v in SG.edges()]\n",
        "\n",
        "    label_nodes = set(ranked[:label_top])\n",
        "    labels = {n:n for n in SG.nodes() if n in label_nodes}\n",
        "\n",
        "    plt.figure(figsize=(10,8))\n",
        "    nx.draw_networkx_edges(SG, pos, width=ewidths, alpha=0.5)\n",
        "    nx.draw_networkx_nodes(SG, pos, node_size=sizes)\n",
        "    nx.draw_networkx_labels(SG, pos, labels=labels, font_size=8)\n",
        "    plt.title(f\"Entity Co-occurrence Network (Top {min(top_n, len(net_summary))}, cleaned)\")\n",
        "    plt.axis(\"off\"); plt.tight_layout(); plt.savefig(savepath, dpi=150); plt.close()"
      ],
      "metadata": {
        "id": "yPtuLU8-2T1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _rotate(ax, deg=45):\n",
        "    for t in ax.get_xticklabels(): t.set_rotation(deg); t.set_ha(\"right\")\n",
        "\n",
        "def plot_bar(df: pd.DataFrame, x: str, y: str, title: str, xlabel: str, ylabel: str, fname: str, horizontal=False):\n",
        "    if isinstance(df, dict):\n",
        "        df = pd.DataFrame(df)\n",
        "    if df is None or df.empty: return\n",
        "    plt.figure()\n",
        "    if horizontal:\n",
        "        plt.barh(df[x][::-1], df[y][::-1])\n",
        "    else:\n",
        "        plt.bar(df[x], df[y])\n",
        "        _rotate(plt.gca(), 45)\n",
        "    plt.title(title); plt.xlabel(xlabel); plt.ylabel(ylabel)\n",
        "    plt.tight_layout(); plt.savefig(fname, dpi=150); plt.close()\n",
        "\n",
        "def plot_line(df: pd.DataFrame, x: str, y: str, title: str, xlabel: str, ylabel: str, fname: str):\n",
        "    if df is None or df.empty: return\n",
        "    plt.figure()\n",
        "    plt.plot(df[x], df[y])\n",
        "    plt.title(title); plt.xlabel(xlabel); plt.ylabel(ylabel)\n",
        "    _rotate(plt.gca(), 45); plt.tight_layout(); plt.savefig(fname, dpi=150); plt.close()"
      ],
      "metadata": {
        "id": "eRHO3WN22c13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _clean_text(s) -> str:\n",
        "    try:\n",
        "        s = \"\" if s is None or (isinstance(s, float) and pd.isna(s)) else str(s)\n",
        "        s = ftfy.fix_text(s)\n",
        "        s = emoji.replace_emoji(s, replace=\"\")\n",
        "        s = re.sub(r\"http\\S+|\\S+@\\S+|#\\w+|@\\w+\", \" \", s)\n",
        "        s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "        return s\n",
        "    except Exception:\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "t4d6damG3r_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean = preprocess(s_data)\n",
        "tables = eda_tables(df_clean)\n",
        "kw_conv = keywords_high_circ_conversion(df_clean, conv_col=\"CONVERSION\")"
      ],
      "metadata": {
        "id": "nWsVGSv42n_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "****"
      ],
      "metadata": {
        "id": "U5fo0nkd5pX6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EDA Visuals of EDA Tables"
      ],
      "metadata": {
        "id": "1yCH9E2D5kxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G, net_summary = eda_network(df_clean)\n",
        "plot_bar(tables[\"top_publications\"].head(15), \"PUBLICATION\",\"count\",\n",
        "         \"Top Publications by Article Count\",\"Publication\",\"Count\",\"eda_top_publications.png\", horizontal=True)\n",
        "\n",
        "plot_bar(tables[\"sources_count_avg_circ\"].head(20), \"PUBLICATION\",\"avg_circ\",\n",
        "         \"Top Publications by Average Circulation\",\"Publication\",\"Avg Circulation\",\"eda_sources_avg_circ.png\", horizontal=True)\n",
        "\n",
        "plot_bar(tables[\"by_source_type\"], \"SOURCE TYPE\",\"count\",\n",
        "         \"Items by Source Type\",\"Source Type\",\"Count\",\"eda_by_source_type.png\")\n",
        "\n",
        "plot_bar(tables[\"by_channel\"], \"CHANNEL\",\"count\",\n",
        "         \"Items by Channel\",\"Channel\",\"Count\",\"eda_by_channel.png\")\n",
        "\n",
        "plot_line(tables[\"volume_daily\"], \"DAY\",\"count\",\"Daily Volume\",\"Day\",\"Count\",\"eda_volume_daily.png\")\n",
        "plot_line(tables[\"volume_weekly\"], \"WEEK\",\"count\",\"Weekly Volume\",\"Week\",\"Count\",\"eda_volume_weekly.png\")\n",
        "plot_line(tables[\"volume_monthly\"], \"MONTH\",\"count\",\"Monthly Volume\",\"Month\",\"Count\",\"eda_volume_monthly.png\")\n",
        "\n",
        "plot_bar(tables[\"overall_sentiment\"], \"overall_bin\",\"count\",\n",
        "         \"Overall Sentiment (Proxy)\",\"Sentiment\",\"Count\",\"eda_overall_sentiment.png\")\n",
        "\n",
        "plot_bar(tables[\"sentiment_by_topic\"], \"topic\",\"count\",\n",
        "         \"Sentiment-Tagged Topics (Total Volume)\",\"Topic\",\"Count\",\"eda_sentiment_by_topic.png\", horizontal=True)\n",
        "\n",
        "plot_bar(kw_conv, \"term\",\"count\",\n",
        "         \"Top Keywords: High-Circulation Conversion Articles\",\"Term\",\"Count\",\"eda_keywords_high_circ_conv.png\", horizontal=True)\n",
        "\n",
        "plot_network_clean(G, net_summary, top_n=40, label_top=12, edge_keep_pct=50, savepath=\"network_top40_clean.png\")\n",
        "\n",
        "print(\"Saved figures:\")\n",
        "for f in [\n",
        "    \"eda_top_publications.png\",\"eda_sources_avg_circ.png\",\n",
        "    \"eda_by_source_type.png\",\"eda_by_channel.png\",\n",
        "    \"eda_volume_daily.png\",\"eda_volume_weekly.png\",\"eda_volume_monthly.png\",\n",
        "    \"eda_overall_sentiment.png\",\"eda_sentiment_by_topic.png\",\n",
        "    \"eda_keywords_high_circ_conv.png\",\"network_top40_clean.png\"\n",
        "]:\n",
        "    print(\"-\", f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0jRjJM-3V9B",
        "outputId": "2ca64911-a0ef-4818-c1bc-dd6f2137ef80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved figures:\n",
            "- eda_top_publications.png\n",
            "- eda_sources_avg_circ.png\n",
            "- eda_by_source_type.png\n",
            "- eda_by_channel.png\n",
            "- eda_volume_daily.png\n",
            "- eda_volume_weekly.png\n",
            "- eda_volume_monthly.png\n",
            "- eda_overall_sentiment.png\n",
            "- eda_sentiment_by_topic.png\n",
            "- eda_keywords_high_circ_conv.png\n",
            "- network_top40_clean.png\n"
          ]
        }
      ]
    }
  ]
}